from datetime import datetime
import datetime
import lxml
from lxml import html
import requests
import pandas as pd
import numpy as np
import pandas_datareader as web
import matplotlib.pyplot as plt

# Ask for the number of stocks the user wants to preselect
number = None
while number is None:
  try:
    number = int(input("Type the number of stocks you want to preselect: "))
  except ValueError:
    print ("You must type an integer, please try again.")

CurrentDate = datetime.date.today()             # dates after this date are in the future and therefore invalid
foundedwallstr = datetime.date(1792, 5, 17)     # dates before this date will be invalid, because the wallstreet wasn't even invented before this date

startdate = None
while startdate is None:
    try:
        startdate = str(input("Enter the start date in YYYY-MM-DD format: "))
        year, month, day = map(int, startdate.split('-'))
        startdate = datetime.date(year, month, day)
        # if the user inputs a higher date than the current
        if startdate > CurrentDate:
            print("Your date can't be in the future, please try again.")
            startdate = None

        # if the user inputs a valid date it's between the current date and the date the wallstreet was founded
        elif foundedwallstr < startdate < CurrentDate:
            print("This date is valid!")
            break

        # if the user inputs a date before there is data
        elif startdate < foundedwallstr:
            print("The stock exchange was in" , startdate, "not even invented, please try again!")
        startdate = None

            # if the user inputs for example letters
    except ValueError:\
        print("You must type a date format, please try again!")
    startdate = None


# Ask for end date
enddate = None
while enddate is None:
  try:
    enddate = str(input("Enter the end date in YYYY-MM-DD format: "))
    year, month, day = map(int, enddate.split('-'))
    enddate = datetime.date(year, month, day)
    delta = enddate - startdate

    # if the user inputs a higher date than the current
    if enddate > CurrentDate:
        print("Your date can't be in the future, please try again.")
        enddate = None

    # if the user inputs two dates which are too close between each other, approx. 179 days
    elif 0 < delta.days < 179:
        print("The delta between start- and end date has to be at least 180 days. Your delta is only", delta.days,"days.")
        enddate = None
        
    # if the user inputs a valid date between the start date and the current date
    elif CurrentDate > enddate > startdate:
        print("This date is valid too!")
        break

    # if the user inputs a date before there is data
    elif enddate < foundedwallstr:
        print("The stock exchange was in", startdate, "not even invented, please try again!")
        enddate = None

    # if the user inputs a lower enddate than the startdate
    elif enddate < startdate:
        print("The end date can't be before the start date.")
        enddate = None

    # if the user inputs for example letters
  except ValueError:\
          print("You must type a date format, please try again!")
  enddate = None
##############################################

# Ask the user to input the tickers
tickers = []
i = 1
while i <= number: 
  try: 
    tick = str(input(f'Enter a {i}th Ticker: ')) 
    tick = tick.upper()
    tickers.append(tick)
    i += 1 
  except ValueError:
    print("Error - you have to enter a string. Try again.") 

# Print the ticker list
print("the ticker list is:", tickers )

# Ask the user to input the risk free rate
riskfree = None
while riskfree is None:
  try:
    riskfree = float(input("Enter the risk free rate in decimals: "))
  except ValueError:
    print ("You must type a float")


# Getting historical stock prices and volume from Yahoo Finance
price_historical = web.get_data_yahoo(tickers,
                           start = startdate,
                           end = enddate)['Adj Close']
                           
volume_historical = web.get_data_yahoo(tickers,
                           start = startdate,
                           end = enddate)['Volume']

# Remove stocks that were not available during this time period and remove the tickers that do not exist
price_historical = price_historical.dropna(axis=1, how='all')

# Computing the log returns
log_ret = np.log(price_historical/price_historical.shift(1))

###################################################################################


# Set up the request headers that we're going to use, to simulate a request by the Chrome browser.
def get_page(url):  
    headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'en-US,en;q=0.9',
        'Cache-Control': 'max-age=0',
        'Pragma': 'no-cache',
        'Referrer': 'https://google.com',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'
    }

    return requests.get(url, headers=headers)

#Ensure that some table rows are found
def parse_rows(table_rows):
    parsed_rows = []

    for table_row in table_rows:
        parsed_row = []
        el = table_row.xpath("./div")

        none_count = 0

        for rs in el:
            try:
                (text,) = rs.xpath('.//span/text()[1]')
                parsed_row.append(text)
            except ValueError:
                parsed_row.append(np.NaN)
                none_count += 1

        if (none_count < 4):
            parsed_rows.append(parsed_row)
            
    return pd.DataFrame(parsed_rows)

# Set the index to the first column: 'Period Ending' and transpose the DataFrame, so that our header contains the account names
def clean_data(df):
    df = df.set_index(0) 
    df = df.transpose() 
    
    # Rename the "Breakdown" column to "Date"
    cols = list(df.columns)
    cols[0] = 'Date'
    df = df.set_axis(cols, axis='columns', inplace=False)
    
    # We convert all columns into float numbers (numeric), except the first column which is the date
    numeric_columns = list(df.columns)[1::] 
    for column_index in range(1, len(df.columns)): 
        df.iloc[:,column_index] = df.iloc[:,column_index].str.replace(',', '') 
        df.iloc[:,column_index] = df.iloc[:,column_index].astype(np.float64) 
        
    return df

def scrape_table(url):
    # Fetch the page that we're going to parse
    page = get_page(url);

    # Parse the page with LXML, so that we can start doing some XPATH queries to extract the data that we want
    tree = html.fromstring(page.content)

    # Fetch all div elements which have class 'D(tbr)'
    table_rows = tree.xpath("//div[contains(@class, 'D(tbr)')]")
    
    # Ensure that some table rows are found
    assert len(table_rows) > 0
    
    df = parse_rows(table_rows)
    df = clean_data(df)
        
    return df

# We scrape data for the balance sheet, the income statement and the cash flow statement 
def scrape(symbol):
    print('Attempting to scrape data for ' + symbol)

    df_balance_sheet = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol)
    df_balance_sheet = df_balance_sheet.set_index('Date')

    df_income_statement = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/financials?p=' + symbol)
    df_income_statement = df_income_statement.set_index('Date')
    
    df_cash_flow = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/cash-flow?p=' + symbol)
    df_cash_flow = df_cash_flow.set_index('Date')
    
    # We create a joint table that will gather data from the balance sheet, the income statement and the statement of cash flows for one ticker in the same table
    df_joined = df_balance_sheet \
        .join(df_income_statement, on='Date', how='outer', rsuffix=' - Income Statement') \
        .join(df_cash_flow, on='Date', how='outer', rsuffix=' - Cash Flow') \
        .dropna(axis=1, how='all') \
        .reset_index()
    
    # We add a column that includes the name of the ticker to allow for a better understanding of the results
    df_joined.insert(1, 'Symbol', symbol) 
    
    return df_joined

# We create a new functions that will allow us to scrape data from the all the tickers list that the user inputed before, and run each of tehm through the scrape function we created before
def scrape_multi(tickers):
    return pd.concat([scrape(symbol) for symbol in tickers], sort=False)

# This is the table that will include gather information from the balance sheet, the income statement and the statement of cash flows for all the stocks selected by the user
df_combined = scrape_multi(tickers)

# We ask the program to display all the columns avialable and not hide some of them
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# We print the table using pandas to obtain a table layout
df_combined_pandas = pd.DataFrame(df_combined)
del df_combined_pandas['index']
display(df_combined_pandas)



# To allow for some comparison between the stocks, we normalize the adjusted closing prices and plot them 
normalized_price_historical = price_historical.pct_change().dropna()
(normalized_price_historical+1).cumprod().plot(figsize=(15,5))
plt.xlabel('Date')
plt.ylabel('Adjusted Closing Price')
plt.title('Evolution of the Adjusted Closing Price')

#Here we display some additional information about the stock historical closing prices
perc =[.20, .40, .60, .80]
print(price_historical.describe(percentiles = perc))



# To allow for some comparison between the stocks, we normalize the volumes traded and plot them 
normalized_volume_historical = volume_historical.pct_change().dropna()
(normalized_volume_historical+1).cumprod().plot(figsize=(15,5))
plt.xlabel('Date')
plt.ylabel('Adjusted Volume Traded')
plt.title('Evolution of the Adjusted Volume Traded')


##################################################################################


# Computing the variance-covariance matrix
cov_mat = log_ret.cov() * 252 #252 trading days in a year
print(cov_mat)

# number of portfolio to simulate
n_portfolio = 7500

# Creating empty arrays to store portfolio weights, return, risk, and sharpe ratio 
all_weights = np.zeros((n_portfolio, len(price_historical.columns)))
port_returns = np.zeros((n_portfolio))
port_risk = np.zeros((n_portfolio))
sharpe_ratio = np.zeros((n_portfolio))

# Simulating the 7500 portfolios and storing their weights, returns, volatility, sharpe ratio
for i in range(n_portfolio):
  # Generating randon weigths using a uniform distribution
  weights = np.random.uniform(size = len(price_historical.columns))
  weights = weights/np.sum(weights)
  
  # Storing weights 
  all_weights[i,:] = weights
  
  # Storing return
  port_ret = np.sum(log_ret.mean() * weights)
  port_ret = (port_ret + 1) ** 252 - 1
  port_returns[i] = port_ret
  
  # Storing risk
  port_sd = np.sqrt(np.dot(weights.T, np.dot(cov_mat, weights)))
  port_risk[i] = port_sd
  
  # Storing Sharpe Ratio  
  sr = (port_ret - riskfree) / port_sd
  sharpe_ratio[i] = sr

names = price_historical.columns

# Finding the minimum variance portfolio
min_var = all_weights[port_risk.argmin()]
print("The weights of the minimum variance portfolio are:", min_var)

# Finding the tangency portfolio
max_sr = all_weights[sharpe_ratio.argmax()]
print("The weights of the maximum sharpe ratio portfolio are:", max_sr)

# Finding the equally weighted portfolio
eq_weights = []
for i in range(len(weights)):
 eq_weights.append(1/len(weights))
print("The weights of the equally weigthed portfolio are:", eq_weights)

# Check if portfolio weights sum to 1
print(sum(min_var), sum(max_sr), sum(eq_weights))


################################################################################
# Here we will display some risk metrics for the minimum variance portfolio

returns_mvp = np.matmul(log_ret, np.transpose(min_var)) #compute the daily returns of the portfolio
mean_annual_ret_mvp = np.mean(returns_mvp)*252 #compute the mean annual return of the portfolio
var_mvp = np.var(returns_mvp)*252 #compute the annual variance of the portfolio
volatility_mvp = np.sqrt(var_mvp) #compute the annual volatility of the portfolio
value_at_risk_mvp = mean_annual_ret_mvp - 1.96*volatility_mvp #compute the annual 95% VaR

print("the mean annual return of the MVP is:", round(mean_annual_ret_mvp, 4))
print("the annual volatility of the MVP is:", round(volatility_mvp, 4))
print("the 95% annual value at risk of the MVP is:", round(value_at_risk_mvp, 4))


# Here we will display some risk metrics for the maximum sharpe ratio portfolio

returns_sr = np.matmul(log_ret, np.transpose(max_sr))
mean_annual_ret_sr = np.mean(returns_sr)*252
var_sr = np.var(returns_sr)*252
volatility_sr = np.sqrt(var_sr)
value_at_risk_sr = mean_annual_ret_sr - 1.96*volatility_sr

print("the mean annual return of the MSRP is:", round(mean_annual_ret_sr, 4))
print("the annual volatility of the MSRP is:", round(volatility_sr, 4))
print("the 95% annual value at risk of the MSRP is:", round(value_at_risk_sr, 4))


# Here we will display some risk metrics for the equally weighted portfolio

returns_eq = np.matmul(log_ret, np.transpose(eq_weights))
mean_annual_ret_eq = np.mean(returns_eq)*252 
var_eq = np.var(returns_eq)*252
volatility_eq = np.sqrt(var_eq)
value_at_risk_eq = mean_annual_ret_eq - 1.96*volatility_eq

print("the mean annual return of the EWP is:", round(mean_annual_ret_eq, 4))
print("the annual volatility of the EWP is:", round(volatility_eq, 4))
print("the 95% annual value at risk of the EWP is:", round(value_at_risk_eq, 4))


################## END OF CODE ###########################





